{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "645d8759",
   "metadata": {},
   "source": [
    "# DATA 620 Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4497ea0",
   "metadata": {},
   "source": [
    "## 1. Importing Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "986930f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f109a0",
   "metadata": {},
   "source": [
    "## 2. Setting up the data Pull\n",
    "\n",
    "### 2.1 Creating a process to get all Reviews\n",
    "\n",
    "We'll start this by creating a function that'll pull 100 reviews at a time and then creating a second function that'll allow us to pull these reviews in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05fe1524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_review_page(appid, cursor, start_date_timestamp, num_per_page, review_type, language):\n",
    "    \"\"\"\n",
    "    Helper function to fetch a single page of Steam reviews for concurrent execution.\n",
    "    Returns a tuple of (reviews, next_cursor, should_stop).\n",
    "    \"\"\"\n",
    "    url = f\"https://store.steampowered.com/appreviews/{appid}\"\n",
    "    params = {\n",
    "        'json': 1,\n",
    "        'filter': 'recent',\n",
    "        'language': language,\n",
    "        'review_type': review_type,\n",
    "        'num_per_page': num_per_page,\n",
    "        'cursor': cursor\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Note: We do not include time.sleep(1) here yet. \n",
    "        # The main function handles the rate limiting across all requests.\n",
    "        response = requests.get(url, params=params, stream=True)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        if data.get('success') != 1:\n",
    "            return ([], None, True) # API call failed\n",
    "\n",
    "        reviews = data.get('reviews', [])\n",
    "        next_cursor = data.get('cursor')\n",
    "        \n",
    "        filtered_reviews = []\n",
    "        should_stop = False\n",
    "\n",
    "        for review in reviews:\n",
    "            review_timestamp = review.get('timestamp_created')\n",
    "            \n",
    "            # Stop if we find a review older than the target date\n",
    "            if review_timestamp and review_timestamp < start_date_timestamp:\n",
    "                should_stop = True\n",
    "                break\n",
    "            \n",
    "            filtered_reviews.append(review)\n",
    "        \n",
    "        return (filtered_reviews, next_cursor, should_stop)\n",
    "\n",
    "    except (requests.exceptions.RequestException, json.JSONDecodeError) as e:\n",
    "        print(f\"An error occurred fetching cursor {cursor[:10]}: {e}\")\n",
    "        return ([], None, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b764f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_steam_reviews_from_2025(appid, num_per_page=100, review_type='all', language='english', max_workers=5):\n",
    "    \"\"\"\n",
    "    Retrieves all user reviews for a Steam App ID posted from January 1st, 2025 onward,\n",
    "    using concurrent requests.\n",
    "    \"\"\"\n",
    "    all_reviews = []\n",
    "    \n",
    "    # Define a fixed start date timestamp (January 1st, 2025)\n",
    "    start_date = datetime(2025, 1, 1)\n",
    "    start_date_timestamp = start_date.timestamp()\n",
    "\n",
    "    print(f\"Starting to fetch reviews for App ID {appid}. Looking for reviews newer than {start_date.strftime('%Y-%m-%d')}.\")\n",
    "\n",
    "    # --- NEW CONCURRENCY LOGIC STARTS HERE ---\n",
    "    \n",
    "    # Cursors to be fetched. Start with the initial cursor '*'.\n",
    "    cursors_to_fetch = ['*']\n",
    "    \n",
    "    # Cursors that are currently being processed or scheduled.\n",
    "    scheduled_cursors = set()\n",
    "    \n",
    "    # We will use a flag to signal when we've hit the chronological limit\n",
    "    stop_fetching = False\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        \n",
    "        futures = {} # Maps future objects to the cursor they are processing\n",
    "\n",
    "        while cursors_to_fetch or futures:\n",
    "            \n",
    "            # 1. Schedule new jobs up to the max_workers limit\n",
    "            while cursors_to_fetch and len(futures) < max_workers:\n",
    "                cursor = cursors_to_fetch.pop(0)\n",
    "                if cursor not in scheduled_cursors:\n",
    "                    print(f\"Scheduling page with cursor: {cursor[:10]}...\")\n",
    "                    future = executor.submit(\n",
    "                        fetch_review_page, \n",
    "                        appid, cursor, start_date_timestamp, num_per_page, review_type, language\n",
    "                    )\n",
    "                    futures[future] = cursor\n",
    "                    scheduled_cursors.add(cursor) # Mark as scheduled\n",
    "\n",
    "            # If no jobs are scheduled and none are running, break\n",
    "            if not futures:\n",
    "                break\n",
    "                \n",
    "            # 2. Process results as they complete\n",
    "            completed_futures = []\n",
    "            for future in futures:\n",
    "                if future.done():\n",
    "                    try:\n",
    "                        reviews, next_cursor, should_stop_page = future.result()\n",
    "                        \n",
    "                        if should_stop_page:\n",
    "                            stop_fetching = True\n",
    "                            \n",
    "                        # Only append if we haven't hit the overall stop flag\n",
    "                        if not stop_fetching:\n",
    "                            all_reviews.extend(reviews)\n",
    "                            \n",
    "                        # If a next cursor is provided, and we're not stopping, add it to the queue\n",
    "                        if next_cursor and not stop_fetching and next_cursor not in scheduled_cursors:\n",
    "                            cursors_to_fetch.append(next_cursor)\n",
    "                        \n",
    "                        print(f\"Page processed. Total reviews: {len(all_reviews)}. Next cursor: {next_cursor[:10] if next_cursor else 'None'}. Stop flag: {should_stop_page}\")\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"Job failed for cursor {futures[future][:10]}: {e}\")\n",
    "                    \n",
    "                    completed_futures.append(future)\n",
    "            \n",
    "            # Remove completed jobs from the dictionary\n",
    "            for future in completed_futures:\n",
    "                del futures[future]\n",
    "\n",
    "            if stop_fetching:\n",
    "                print(\"Chronological limit reached by a worker. Shutting down executor.\")\n",
    "                # Cancel pending jobs and stop scheduling new ones\n",
    "                for future in futures:\n",
    "                    future.cancel()\n",
    "                break\n",
    "\n",
    "            # Add a small delay to avoid busy-waiting, but be mindful of Steam's rate limit\n",
    "            # Note: Parallel fetching already means higher rate, so the inherent delay \n",
    "            # while waiting for results helps, but we might need a more controlled throttling \n",
    "            # if this were a production system.\n",
    "            time.sleep(0.5)\n",
    "\n",
    "    return all_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b09391",
   "metadata": {},
   "source": [
    "### 2.2 Creating a process to get all Steam App IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23b193a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_steam_appids():\n",
    "    \"\"\"\n",
    "    Fetches the list of all Steam applications and their App IDs using the\n",
    "    GetAppList API endpoint.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of dictionaries, where each dict has keys 'appid' and 'name'.\n",
    "        Returns an empty list if the API call fails.\n",
    "    \"\"\"\n",
    "    url = \"https://api.steampowered.com/ISteamApps/GetAppList/v2/\"\n",
    "    \n",
    "    print(\"ðŸš€ Fetching complete list of all Steam applications. This may take a moment...\")\n",
    "    \n",
    "    try:\n",
    "        # Steam's GetAppList is a public, unauthenticated endpoint\n",
    "        response = requests.get(url, timeout=30)\n",
    "        response.raise_for_status() # Raise an exception for bad status codes\n",
    "        \n",
    "        data = response.json()\n",
    "        \n",
    "        # Navigate the JSON structure to the list of apps\n",
    "        apps = data.get('applist', {}).get('apps', [])\n",
    "        \n",
    "        print(f\"âœ… Successfully retrieved {len(apps):,} applications.\")\n",
    "        return apps\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"âŒ API request failed: {e}\")\n",
    "        return []\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"âŒ Failed to decode JSON response.\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f42820",
   "metadata": {},
   "source": [
    "## 3. Retrieve Steam Reviews\n",
    "### 3.1 Getting all Steam App IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0f82cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Fetching complete list of all Steam applications. This may take a moment...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Successfully retrieved 276,345 applications.\n",
      "Starting to fetch reviews for App ID 5. Looking for reviews newer than 2025-01-01.\n",
      "Scheduling page with cursor: *...\n",
      "Page processed. Total reviews: 0. Next cursor: *. Stop flag: False\n",
      "Starting to fetch reviews for App ID 7. Looking for reviews newer than 2025-01-01.\n",
      "Scheduling page with cursor: *...\n",
      "Page processed. Total reviews: 0. Next cursor: *. Stop flag: False\n",
      "Starting to fetch reviews for App ID 8. Looking for reviews newer than 2025-01-01.\n",
      "Scheduling page with cursor: *...\n",
      "Page processed. Total reviews: 0. Next cursor: *. Stop flag: False\n",
      "Starting to fetch reviews for App ID 10. Looking for reviews newer than 2025-01-01.\n",
      "Scheduling page with cursor: *...\n",
      "Page processed. Total reviews: 100. Next cursor: AoJ4i5rI+5. Stop flag: False\n",
      "Scheduling page with cursor: AoJ4i5rI+5...\n",
      "Page processed. Total reviews: 200. Next cursor: AoJww8qb0p. Stop flag: False\n",
      "Scheduling page with cursor: AoJww8qb0p...\n",
      "Page processed. Total reviews: 300. Next cursor: AoJ4saLjoZ. Stop flag: False\n",
      "Scheduling page with cursor: AoJ4saLjoZ...\n",
      "Page processed. Total reviews: 400. Next cursor: AoJwlvub7Z. Stop flag: False\n",
      "Scheduling page with cursor: AoJwlvub7Z...\n",
      "Page processed. Total reviews: 500. Next cursor: AoJw6a/Gv5. Stop flag: False\n",
      "Scheduling page with cursor: AoJw6a/Gv5...\n",
      "Page processed. Total reviews: 600. Next cursor: AoJw8u7Gjp. Stop flag: False\n",
      "Scheduling page with cursor: AoJw8u7Gjp...\n",
      "Page processed. Total reviews: 700. Next cursor: AoJ47/6y55. Stop flag: False\n",
      "Scheduling page with cursor: AoJ47/6y55...\n",
      "Page processed. Total reviews: 800. Next cursor: AoJw9L6bxZ. Stop flag: False\n",
      "Scheduling page with cursor: AoJw9L6bxZ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mGame \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msteam_app[\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m data already downloaded. Skipping.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     reviews = \u001b[43mget_steam_reviews_from_2025\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mappid\u001b[49m\u001b[43m=\u001b[49m\u001b[43msteam_app\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mappid\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_per_page\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreview_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mall\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43menglish\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(save_filepath, \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     17\u001b[39m         json.dump(reviews, f, ensure_ascii=\u001b[38;5;28;01mFalse\u001b[39;00m, indent=\u001b[32m4\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 87\u001b[39m, in \u001b[36mget_steam_reviews_from_2025\u001b[39m\u001b[34m(appid, num_per_page, review_type, language, max_workers)\u001b[39m\n\u001b[32m     81\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     83\u001b[39m         \u001b[38;5;66;03m# Add a small delay to avoid busy-waiting, but be mindful of Steam's rate limit\u001b[39;00m\n\u001b[32m     84\u001b[39m         \u001b[38;5;66;03m# Note: Parallel fetching already means higher rate, so the inherent delay \u001b[39;00m\n\u001b[32m     85\u001b[39m         \u001b[38;5;66;03m# while waiting for results helps, but we might need a more controlled throttling \u001b[39;00m\n\u001b[32m     86\u001b[39m         \u001b[38;5;66;03m# if this were a production system.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m all_reviews\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for steam_app in get_all_steam_appids():\n",
    "    save_filename = f\"{steam_app['appid']}.json\"\n",
    "    save_filepath = f\"data/{save_filename}\"\n",
    "    \n",
    "    if os.path.exists(save_filepath):\n",
    "        print(f'Game \"{steam_app['name']}\" data already downloaded. Skipping.')\n",
    "    \n",
    "    else:\n",
    "        reviews = get_steam_reviews_from_2025(\n",
    "            appid=steam_app['appid'],\n",
    "            num_per_page=100,\n",
    "            review_type='all',\n",
    "            language='english'\n",
    "        )\n",
    "\n",
    "        with open(save_filepath, 'w', encoding='utf-8') as f:\n",
    "            json.dump(reviews, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4de625",
   "metadata": {},
   "source": [
    "## 4. Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a78309",
   "metadata": {},
   "source": [
    "### 4.1 Data Prep & Text Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004426f5",
   "metadata": {},
   "source": [
    "### 4.2 Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341f2f1e",
   "metadata": {},
   "source": [
    "## 5. Network Analysis for Reviewers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33edfc2c",
   "metadata": {},
   "source": [
    "### 5.1 Network Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b81461d",
   "metadata": {},
   "source": [
    "### 5.2 Core Network Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bb16296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Results Summary ---\n",
      "Total English reviews from the last year: **99**\n",
      "Newest Review Timestamp: 2025-11-08 12:58:02\n",
      "Oldest Review Timestamp: 2025-11-08 07:37:14\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Final Results Summary ---\")\n",
    "print(f\"Total English reviews from the last year: **{len(recent_reviews)}**\")\n",
    "\n",
    "if recent_reviews:\n",
    "    # Check the timestamp of the newest and oldest found review\n",
    "    newest_ts = max(r['timestamp_created'] for r in recent_reviews)\n",
    "    oldest_ts = min(r['timestamp_created'] for r in recent_reviews)\n",
    "    \n",
    "    print(f\"Newest Review Timestamp: {datetime.fromtimestamp(newest_ts).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"Oldest Review Timestamp: {datetime.fromtimestamp(oldest_ts).strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b18e4af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recommendationid': '208734320',\n",
       " 'author': {'steamid': '76561199089646276',\n",
       "  'num_games_owned': 0,\n",
       "  'num_reviews': 2,\n",
       "  'playtime_forever': 16372,\n",
       "  'playtime_last_two_weeks': 1606,\n",
       "  'playtime_at_review': 16372,\n",
       "  'last_played': 1762623802},\n",
       " 'language': 'english',\n",
       " 'review': 'worst game ever.. love it',\n",
       " 'timestamp_created': 1762623822,\n",
       " 'timestamp_updated': 1762623822,\n",
       " 'voted_up': True,\n",
       " 'votes_up': 0,\n",
       " 'votes_funny': 0,\n",
       " 'weighted_vote_score': 0.5,\n",
       " 'comment_count': 0,\n",
       " 'steam_purchase': True,\n",
       " 'received_for_free': False,\n",
       " 'written_during_early_access': False,\n",
       " 'primarily_steam_deck': False}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf87d86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data620env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
